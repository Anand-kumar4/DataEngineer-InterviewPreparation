


# Day 4 â€“ PySpark + SQL Interview Practice

This folder contains daily coding problems focused on **PySpark** and **SQL**, covering transformations, aggregations, and conditional logic often asked in Data Engineering interviews.

## âœ… Problems Covered

1. **Group Books per User**  
   ğŸ“„ `books_purchased.csv`  
   ğŸ§  Use: `collect_list`, `concat_ws`

2. **Users with All NULL Purchases**  
   ğŸ“„ `books_purchased_problem2.csv`  
   ğŸ§  Use: `count`, `isNull`, `having count(*) = 0`

3. **Top Region by Average Revenue per Product**  
   ğŸ“„ `sales_region.csv`  
   ğŸ§  Use: `groupBy`, `avg`, `dense_rank`

4. **Flag High vs Low Value Transactions**  
   ğŸ“„ `transactions_flag.csv`  
   ğŸ§  Use: `when`, `otherwise`, `CASE WHEN`

5. **Customers with Exactly 2 Distinct Purchase Amounts**  
   ğŸ“„ `distinct_amounts.csv`  
   ğŸ§  Use: `countDistinct`, `having = 2`

6. **First Purchase per Customer**  
   ğŸ“„ `first_purchases.csv`  
   ğŸ§  Use: `row_number`, `orderBy`, `partitionBy`

7. **Customers with Repeat Purchases (Same Product)**  
   ğŸ“„ `repeat_purchases.csv`  
   ğŸ§  Use: `groupBy`, `count > 1`

## ğŸ“ Folder Structure

```
Day4/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ books_purchased.csv
â”‚   â”œâ”€â”€ books_purchased_problem2.csv
â”‚   â”œâ”€â”€ sales_region.csv
â”‚   â”œâ”€â”€ transactions_flag.csv
â”‚   â”œâ”€â”€ distinct_amounts.csv
â”‚   â”œâ”€â”€ first_purchases.csv
â”‚   â””â”€â”€ repeat_purchases.csv
â”œâ”€â”€ pyspark/
â”‚   â”œâ”€â”€ group_books_per_user.py
â”‚   â”œâ”€â”€ users_with_all_null_purchases.py
â”‚   â”œâ”€â”€ top_region_by_avg_revenue.py
â”‚   â”œâ”€â”€ flag_high_low_transactions.py
â”‚   â”œâ”€â”€ customers_with_two_distinct_amounts.py
â”‚   â”œâ”€â”€ first_purchase_per_customer.py
â”‚   â””â”€â”€ customers_with_repeat_purchases.py
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ group_books_per_user.sql
â”‚   â”œâ”€â”€ users_with_all_null_purchases.sql
â”‚   â”œâ”€â”€ top_region_by_avg_revenue.sql
â”‚   â”œâ”€â”€ flag_high_low_transactions.sql
â”‚   â”œâ”€â”€ customers_with_two_distinct_amounts.sql
â”‚   â”œâ”€â”€ first_purchase_per_customer.sql
â”‚   â””â”€â”€ customers_with_repeat_purchases.sql
```

## ğŸ§  Goal

Practice hands-on PySpark and SQL transformations, filtering, grouping, window functions, and more â€” exactly the kinds of logic expected in real-world data engineering interviews.