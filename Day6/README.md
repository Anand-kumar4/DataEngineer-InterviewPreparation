# ğŸ“˜ Day 6 â€“ PySpark + SQL Interview Practice

As part of my ongoing data engineering interview preparation, here are 7 advanced and medium-complexity problems solved using both **PySpark** and **SQL**.

---

## ğŸ§  Problems Covered

| No. | Problem Title                                      | Description |
|-----|----------------------------------------------------|-------------|
| 1ï¸âƒ£  | Monthly Top Spenders                               | Identify top monthly spender per customer |
| 2ï¸âƒ£  | Order-to-Delivery Duration                          | Calculate duration between order and delivery |
| 3ï¸âƒ£  | Join Orders with First Product Purchased           | For each order, tag the first product purchased by that customer |
| 4ï¸âƒ£  | Category-wise Revenue % Contribution               | Calculate product's contribution to its categoryâ€™s total revenue |
| 5ï¸âƒ£  | Repeat Buyers Within a Week                        | Detect customers who made 2 purchases within 7 days |
| 6ï¸âƒ£  | Sessionize Web Events                              | Assign session IDs based on 30-minute activity gaps |
| 7ï¸âƒ£  | Product Category Popularity Trends                 | Track monthly sales trends (UP/DOWN/SAME) per category |

---

## ğŸ“ Folder Structure

```
Day6/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ category_monthly_sales.csv
â”‚   â”œâ”€â”€ category_sales.csv
â”‚   â”œâ”€â”€ consecutive_purchases.csv
â”‚   â”œâ”€â”€ monthly_transactions.csv
â”‚   â”œâ”€â”€ orders_delivery.csv
â”‚   â”œâ”€â”€ orders_with_products.csv
â”‚   â”œâ”€â”€ repeat_buyers.csv
â”‚   â””â”€â”€ web_events.csv
â”œâ”€â”€ pyspark/
â”‚   â”œâ”€â”€ category_popularity_trend.py
â”‚   â”œâ”€â”€ category_revenue_contribution.py
â”‚   â”œâ”€â”€ consecutive_purchase_streaks.py
â”‚   â”œâ”€â”€ monthly_top_spenders.py
â”‚   â”œâ”€â”€ order_delivery_duration.py
â”‚   â”œâ”€â”€ repeat_buyers_within_week.py
â”‚   â””â”€â”€ sessionize_web_events.py
â””â”€â”€ sql/
    â”œâ”€â”€ category_popularity_trend.sql
    â”œâ”€â”€ category_revenue_contribution.sql
    â”œâ”€â”€ consecutive_purchase_streaks.sql
    â”œâ”€â”€ monthly_top_spenders.sql
    â”œâ”€â”€ order_delivery_duration.sql
    â”œâ”€â”€ repeat_buyers_within_week.sql
    â””â”€â”€ sessionize_web_events.sql
```

---

## âœ… Goal

Practice key transformations and logic patterns used in real-world data engineering interviews â€” using both PySpark (for scalable distributed processing) and SQL (for analytics and warehousing logic).

---

## ğŸ”— Connect

Follow my journey or connect on [LinkedIn](https://www.linkedin.com/in/anand-kumar-singh-830839ab)

#DataEngineering #PySpark #SQL #InterviewPreparation
